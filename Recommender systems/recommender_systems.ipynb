{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*   [Before we start](#before-we-start)\n",
    "*   [Introduction](#introduction)\n",
    "*   [Data](#data)\n",
    "*   [Matrix representation](#matrix)\n",
    "*   [Collaborative filtering](#collaborative-filtering)\n",
    "    *   [Euclidian distance](#euclidian-distance)\n",
    "    *   [Cosine similarity](#cosine-similarity)\n",
    "    *   [Prediction](#prediction)\n",
    "    *   [Using Surprise](#surprise)\n",
    "*   [SVD](#svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start<a id=\"before-we-start\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [Pandas](https://pandas.pydata.org/), [Scikit-learn](https://scikit-learn.org/), [Surprise](https://surpriselib.com/), [NumPy](https://numpy.org/), and [SciPy](https://scipy.org/) in this notebook. Surprise is a Python toolkit that can be used to quickly create small-scale recommender systems. Its documentation can be found [here](https://surprise.readthedocs.io/en/stable/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction<a id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems are everywhere today. We use them to find movies to watch, articles to read, items to buy, and people to follow. Different kinds of recommender systems use different filtering methods. A common classification is as follows:\n",
    "*   Content-based filtering: These systems allow us to filter contents based on some metadata. For example, filtering movies based on genre is a content-based filtering.\n",
    "*   Collaborative filtering: These systems measure a recommended item's relevance by using the user's or the item's data in collaboration with other users' or items' data.\n",
    "    *   Model-based: With this approach, the system uses a trained model to predict the relevance of an item for a person.\n",
    "    *   Memory-based: With this approach, the system directly uses data of the users or items to come up with recommendations. This is more straightforward than a model-based approach, but it is more memory-intensive.\n",
    "        *   User-based: Recommendations are made using the user's similarity to other users. If we want to predict someone's rating for a movie, we look at people who are similar to this user, and use their rating for that movie. \n",
    "        *   Item-based: Recommendations are made using the item's similarity to other items. If we want to predict someone's rating for a movie, we look at other movies that are similar to that movie and use that person's rating for those movies. \n",
    "*   Hybrid filtering: These systems combine content-based and collaborative filtering, which usually is the case in real-life systems. We can specify a genre we want to watch, and thousands of movies from that genre can be served in an order defined by collaborative filtering methods.\n",
    "\n",
    "In this notebook, we will explore model-based and memory-based approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data<a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a preprocessed sample from [a Netflix recommendation dataset](https://www.kaggle.com/netflix-inc/netflix-prize-data). Two files are provided with this notebook. One of them is a movie dataset that includes the ID, release date, and title of movies. One problem is the title column is not quoted, so commas in titles cause issues during import. To solve this, we will use Python's CSV reader, split lines using commas, and limit the number of splits for a line to two. This way, commas that come after the last real separator are ignored. We will then create a DataFrame object from these split lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2004</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17764</th>\n",
       "      <td>17766</td>\n",
       "      <td>2002</td>\n",
       "      <td>Where the Wild Things Are and Other Maurice Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17765</th>\n",
       "      <td>17767</td>\n",
       "      <td>2004</td>\n",
       "      <td>Fidel Castro: American Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17766</th>\n",
       "      <td>17768</td>\n",
       "      <td>2000</td>\n",
       "      <td>Epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17767</th>\n",
       "      <td>17769</td>\n",
       "      <td>2003</td>\n",
       "      <td>The Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17768</th>\n",
       "      <td>17770</td>\n",
       "      <td>2003</td>\n",
       "      <td>Alien Hunter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17769 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Year                                              Title\n",
       "0          1  2003                                    Dinosaur Planet\n",
       "1          2  2004                         Isle of Man TT 2004 Review\n",
       "2          3  1997                                          Character\n",
       "3          4  1994                       Paula Abdul's Get Up & Dance\n",
       "4          5  2004                           The Rise and Fall of ECW\n",
       "...      ...   ...                                                ...\n",
       "17764  17766  2002  Where the Wild Things Are and Other Maurice Se...\n",
       "17765  17767  2004                  Fidel Castro: American Experience\n",
       "17766  17768  2000                                              Epoch\n",
       "17767  17769  2003                                        The Company\n",
       "17768  17770  2003                                       Alien Hunter\n",
       "\n",
       "[17769 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"movies_dataset.csv\", \"r\", newline=\"\\n\") as file:\n",
    "    movies = [line.split(\",\", 2) for line in file.read().splitlines()]\n",
    "    movies = pd.DataFrame(movies, columns=[\"ID\", \"Year\", \"Title\"]) # Creating a DataFrame\n",
    "    movies = movies.astype({\"ID\": int}) # Converting IDs to integers\n",
    "    \n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other file includes user ratings for each film. Each user has rated at least 300 movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie ID</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1488844</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-09-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>30878</td>\n",
       "      <td>4</td>\n",
       "      <td>2005-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1248029</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-04-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1080361</td>\n",
       "      <td>3</td>\n",
       "      <td>2005-03-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>558634</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-12-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956128</th>\n",
       "      <td>4499</td>\n",
       "      <td>811530</td>\n",
       "      <td>4</td>\n",
       "      <td>2004-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956129</th>\n",
       "      <td>4499</td>\n",
       "      <td>1852040</td>\n",
       "      <td>1</td>\n",
       "      <td>2004-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956130</th>\n",
       "      <td>4499</td>\n",
       "      <td>303969</td>\n",
       "      <td>2</td>\n",
       "      <td>2004-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956131</th>\n",
       "      <td>4499</td>\n",
       "      <td>654591</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956132</th>\n",
       "      <td>4499</td>\n",
       "      <td>1704416</td>\n",
       "      <td>3</td>\n",
       "      <td>2004-06-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2956133 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Movie ID  User ID  Rating       Date\n",
       "0               1  1488844       3 2005-09-06\n",
       "1               1    30878       4 2005-12-26\n",
       "2               1  1248029       3 2004-04-22\n",
       "3               1  1080361       3 2005-03-28\n",
       "4               1   558634       4 2004-12-14\n",
       "...           ...      ...     ...        ...\n",
       "2956128      4499   811530       4 2004-07-28\n",
       "2956129      4499  1852040       1 2004-05-13\n",
       "2956130      4499   303969       2 2004-05-23\n",
       "2956131      4499   654591       3 2004-04-26\n",
       "2956132      4499  1704416       3 2004-06-02\n",
       "\n",
       "[2956133 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"ratings_dataset.csv\")\n",
    "ratings[\"Date\"] = pd.to_datetime(ratings[\"Date\"]) # We might want to deal with dates\n",
    "\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4499 unique movies\n",
      "7086 unique users\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings[\"Movie ID\"].unique()), \"unique movies\")\n",
    "print(len(ratings[\"User ID\"].unique()), \"unique users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our movies dataset has 17769 movies, our rating dataset has 4499 unique movies and 7086 unique users. Looking at the number of movies users rated, we obtain a Zipfian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ratings.groupby(\"User ID\").size().plot.density(xlim=[300,None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix representation<a id=\"matrix\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent these ratings as a matrix of user-movie pairs. To convert the rating dataset into a matrix, we can use the `pivot_table` method with a DataFrame object. We want each row to represent a user and each column to represent a movie, so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Movie ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>4490</th>\n",
       "      <th>4491</th>\n",
       "      <th>4492</th>\n",
       "      <th>4493</th>\n",
       "      <th>4494</th>\n",
       "      <th>4495</th>\n",
       "      <th>4496</th>\n",
       "      <th>4497</th>\n",
       "      <th>4498</th>\n",
       "      <th>4499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646634</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647197</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647888</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648589</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648885</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7086 rows Ã— 4499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Movie ID  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "User ID                                                               ...   \n",
       "1333       NaN   NaN   4.0   NaN   NaN   NaN   NaN   3.0   NaN   NaN  ...   \n",
       "2213       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2787       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2976       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "3321       3.0   NaN   NaN   NaN   4.0   NaN   NaN   1.0   NaN   NaN  ...   \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "2646634    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2647197    NaN   NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN  ...   \n",
       "2647888    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2648589    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "2648885    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   \n",
       "\n",
       "Movie ID  4490  4491  4492  4493  4494  4495  4496  4497  4498  4499  \n",
       "User ID                                                               \n",
       "1333       NaN   NaN   NaN   NaN   NaN   NaN   2.0   NaN   NaN   NaN  \n",
       "2213       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2787       NaN   NaN   2.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2976       4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3321       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2646634    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2647197    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2647888    NaN   NaN   4.0   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2648589    NaN   NaN   NaN   NaN   NaN   NaN   3.0   NaN   NaN   NaN  \n",
       "2648885    NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[7086 rows x 4499 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix = ratings.pivot_table(index=\"User ID\", columns=\"Movie ID\", values=\"Rating\")\n",
    "\n",
    "rating_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most people rate only a fraction of the possible items, these matrices are commonly sparse, especially in real-life scenarios.\n",
    "\n",
    "We should be careful that row/column indices are not the same with IDs. For example, the first row represents User 1333. If we want to access a user using their ID, we need to use `loc`. If we want to access a user using their index among all users, we need to use `iloc`.\n",
    "\n",
    "This retrieves the first row's third column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix.iloc[0,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This retrieves User 1333's rating for Movie 3 (which corresponds to the same thing as above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix.loc[1333,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to have a conversion method between indices and IDs for users and movies. For this reason, we can create some conversion dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id_to_index = {user_id: index for index, user_id in enumerate(rating_matrix.index)}\n",
    "user_index_to_id = {index: user_id for user_id, index in user_id_to_index.items()} # Reversed\n",
    "\n",
    "movie_id_to_index = {movie_id: index for index, movie_id in enumerate(rating_matrix.columns)}\n",
    "movie_index_to_id = {index: movie_id for movie_id, index in movie_id_to_index.items()} # Reversed\n",
    "\n",
    "user_id_to_index[1333]\n",
    "# user_index_to_id[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering<a id=\"collaborative-filtering\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidian distance<a id=\"euclidian-distance\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider these three users, four movies, and their ratings:\n",
    "    \n",
    "<table>\n",
    "    <tr>\n",
    "        <td></td>\n",
    "        <td><b>Movie 1</b></td>\n",
    "        <td><b>Movie 2</b></td>\n",
    "        <td><b>Movie 3</b></td>\n",
    "        <td><b>Movie 4</b></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>User 1</b></td>\n",
    "        <td>1</td>\n",
    "        <td>4</td>\n",
    "        <td>4</td>\n",
    "        <td style=\"color: red;\">?</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>User 2</b></td>\n",
    "        <td>2</td>\n",
    "        <td>3</td>\n",
    "        <td>4</td>\n",
    "        <td>5</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td><b>User 3</b></td>\n",
    "        <td>4</td>\n",
    "        <td>2</td>\n",
    "        <td>1</td>\n",
    "        <td>1</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we want to predict User 1's rating for Movie 3. How can we make use of the other users' ratings? User 2 has rated Movie 3 as 5 while User 3 has rated it as 1. What could be User 1's rating for this movie?\n",
    "\n",
    "Intuitively, we can say that User 1's rating would probably be closer to 5 rather than 1 because User 1 has more similar ratings with User 2 than with User 3. We can measure this similarity by calculating the **Euclidian distance** between User 1 and the other users using the jointly rated movies:\n",
    "\n",
    "$distance(User\\;1, User\\;2) =  \\sqrt{(1-2)^2 + (4-3)^2 + (4-4)^2} \\approx 1.41$\n",
    "\n",
    "$distance(User\\;1, User\\;2) =  \\sqrt{(1-4)^2 + (4-2)^2 + (4-1)^2} \\approx 4.69 $\n",
    "\n",
    "User 2 is indeed closer as their distance is much smaller. However, this distance metric is harder to interpret. The moment we add a new movie or change the rating scale, distances change without an upper bound, which makes it harder to compare distances before and after changes. For this reason, we prefer to use cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity<a id=\"cosine-similarity\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In linear algebra, we compare two non-zero vectors' similarity by looking at the angle between them. If two normalized vectors are the same, their angle is 0 degrees. If they are the exact opposites, they are orthogonal, so they are 90 degrees apart. Cosine similarity is based on the cosine of their angle. Since cosine can take a value between cos(0) = 0 and cos(90) = 1, we can easily interpret two vectors' similarities using the cosine similarity. A cosine similarity of 0.9 suggests a 90% similarity between the two vectors.\n",
    "\n",
    "If we do not know the angle itself, we can calculate the **cosine similarity** as follows:\n",
    "\n",
    "$similarity(A, B) = \\dfrac{A \\cdot B}{||A|| \\times ||B||}$\n",
    "\n",
    "This calculates the dot product of two vectors and divides it by the multiplication of their magnitudes (lengths), which normalizes the vectors in the process.\n",
    "\n",
    "The **dot product** of two vectors are calculated as follows:\n",
    "\n",
    "$A \\cdot B = a_1 b_1 + a_2 b_2 + a_3 b_3 + ... + a_n b_n $\n",
    "\n",
    "The **magnitude** of a vector can be calculated as follows:\n",
    "\n",
    "$||A|| = \\sqrt{a_1^2 + a_2^2 + a_3^2 + ... + a_n^2}$\n",
    "\n",
    "Alternatively, the magnitude can be also considered as the square root of the dot product of a vector with itself.\n",
    "\n",
    "Now, let us calculate the cosine similarity with User 1 and the other users:\n",
    "\n",
    "$similarity(User\\;1, User\\;2) = \\dfrac{1 \\times 2 + 4 \\times 3 + 4 \\times 4}{\\sqrt{1^2 + 4^2 + 4^2} \\times \\sqrt{2^2 + 3^2 + 4^2}} \\approx 0.97 $\n",
    "\n",
    "$similarity(User\\;1, User\\;3) = \\dfrac{1 \\times 4 + 4 \\times 2 + 4 \\times 1}{\\sqrt{1^2 + 4^2 + 4^2} \\times \\sqrt{4^2 + 2^2 + 1^2}} \\approx 0.61 $\n",
    "\n",
    "This is much more interpretable. Note that the cosine similarity of two vectors produces the same result as taking the Euclidian distance of two vectors normalized by their magnitudes.\n",
    "\n",
    "Now that we know how to evaluate vector distances, we can find the $k$ closest users to predict a user's rating. This is user-based collaborative filtering because we use other users' data to predict a specific user's rating.\n",
    "\n",
    "Before we continue, we need to solve an issue. While calculating the cosine similarity, we will either remove all movies that are not rated by the two compared people or we need to assign such a value that would enable us to directly use the matrix without affecting the results. Considering the formulas given above, we can set any non-rated movie's rating to 0 so that they do not affect similarity (check the formulas above to see why it works):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Movie ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>4490</th>\n",
       "      <th>4491</th>\n",
       "      <th>4492</th>\n",
       "      <th>4493</th>\n",
       "      <th>4494</th>\n",
       "      <th>4495</th>\n",
       "      <th>4496</th>\n",
       "      <th>4497</th>\n",
       "      <th>4498</th>\n",
       "      <th>4499</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646634</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647888</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648589</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2648885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7086 rows Ã— 4499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Movie ID  1     2     3     4     5     6     7     8     9     10    ...  \\\n",
       "User ID                                                               ...   \n",
       "1333       0.0   0.0   4.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0  ...   \n",
       "2213       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2787       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2976       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3321       3.0   0.0   0.0   0.0   4.0   0.0   0.0   1.0   0.0   0.0  ...   \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   \n",
       "2646634    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2647197    0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  ...   \n",
       "2647888    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2648589    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2648885    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "Movie ID  4490  4491  4492  4493  4494  4495  4496  4497  4498  4499  \n",
       "User ID                                                               \n",
       "1333       0.0   0.0   0.0   0.0   0.0   0.0   2.0   0.0   0.0   0.0  \n",
       "2213       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2787       0.0   0.0   2.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2976       4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3321       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "...        ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "2646634    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2647197    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2647888    0.0   0.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2648589    0.0   0.0   0.0   0.0   0.0   0.0   3.0   0.0   0.0   0.0  \n",
       "2648885    0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[7086 rows x 4499 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_matrix = rating_matrix.fillna(0)\n",
    "\n",
    "rating_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use scikit-learn's `cosine_similarity` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7086, 7086)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(rating_matrix, dense_output=False)\n",
    "\n",
    "similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a similarity matrix that gives us the similarity between any two people. For example, the similarity between the first two users is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35391132837717354"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to work with IDs rather than indices, we could use the conversion dictionary. Using the first two users' IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35391132837717354"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix[user_id_to_index[1333],user_id_to_index[2213]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users having the perfect similarity with themselves can be problematic for us. To overcome this, we can simply change the values in the diagonal to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(0, len(similarity_matrix)):\n",
    "    similarity_matrix[i,i] = 0\n",
    "    \n",
    "similarity_matrix[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the closest user to the first user, we can now take their row and find the index that gives the highest similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7009"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5445107847478888"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix[0,7009]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, multiple indices may have the same similarity, or we may want to retrieve the top 10 similar users. In such cases, we can use `argpartition` and get the top $k$ users with the highest similarity and reverse the array so users are sorted by their similarity in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar users:\n",
      "User 2621962 - 0.5445107847478888\n",
      "User 2365581 - 0.5427140161727015\n",
      "User 1830000 - 0.5406106559588392\n",
      "User 1984315 - 0.5401233893165944\n",
      "User 307427 - 0.538353890250029\n",
      "User 1764923 - 0.5376539973464769\n",
      "User 872408 - 0.5359535241036087\n",
      "User 603277 - 0.5325616983861338\n",
      "User 983042 - 0.5310395722287413\n",
      "User 322009 - 0.5291417764517407\n"
     ]
    }
   ],
   "source": [
    "k = 10 # Top 10 similar users\n",
    "\n",
    "# Top k users\n",
    "top_similar_user_indices = np.argpartition(similarity_matrix[0], kth=-k)[-k:]\n",
    "\n",
    "# Top k users sorted by their similarity in descending order\n",
    "top_similar_user_indices = top_similar_user_indices[np.argsort(similarity_matrix[0][top_similar_user_indices])][::-1] \n",
    "\n",
    "print(\"Top similar users:\")\n",
    "for similar_user_index in top_similar_user_indices:\n",
    "    print(\"User\",user_index_to_id[similar_user_index],\"-\",similarity_matrix[0,similar_user_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction<a id=\"prediction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding $k$ similar users, we can predict a rating by looking at their ratings. To do so, we can simply average non-zero ratings of similar users. However, this would give equal weight to them. We may want to give more weight to more similar users. For this reason, we can use a weighted average where weight is their similarity with User 1. Be careful that indices and IDs are different, and we need to use `loc` for IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5031977174475917"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_sum = 0\n",
    "weight_sum = 0\n",
    "\n",
    "prediction_movie_id = 1\n",
    "\n",
    "for similar_user_index in top_similar_user_indices:\n",
    "    similar_user_id = user_index_to_id[similar_user_index]\n",
    "    rating = rating_matrix.loc[similar_user_id, prediction_movie_id]\n",
    "    if rating == 0:\n",
    "        continue\n",
    "        \n",
    "    weight = similarity_matrix[0,similar_user_index]\n",
    "    weight_sum += weight\n",
    "    rating_sum += rating * weight\n",
    "    \n",
    "prediction = rating_sum/weight_sum\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we predict that User 1 will rate Movie 1 as 3.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Surprise<a id=\"surprise\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We managed to create the backbone of a simple recommender system with minimal help. We could create a prediction function that wraps the process of finding $k$ similar users and predicting a rating. We could also use a package like [Surprise](https://surprise.readthedocs.io/en/stable/getting_started.html) that handles all these processes for us.\n",
    "\n",
    "Firstly, we need to obtain the data in a compatible format. Surprise wants our data in a format similar to the original DataFrame. We will also split our dataset into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import Reader, Dataset, KNNBaseline\n",
    "\n",
    "# Splitting the dataset\n",
    "training_data, test_data = train_test_split(ratings[[\"User ID\", \"Movie ID\", \"Rating\"]], test_size=0.1, random_state=42)\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# Converting the DataFrame to a Dataset object for Surprise\n",
    "training_data = Dataset.load_from_df(training_data, reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x23ff2162888>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = KNNBaseline(k=10, min_k=2, sim_options={\"name\": \"cosine\", \"user_based\": True})\n",
    "algo.fit(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us predict User 1333's rating for Movie 1 again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1333, iid=1, r_ui=None, est=3.2283924885804747, details={'actual_k': 10, 'was_impossible': False})]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.test([[1333,1,None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We had previously predicted 3.5 using manual calculations and the whole dataset. The algorithm here predicts 3.23 using the training set.\n",
    "\n",
    "The nice thing about having training and validation sets is we can compare the predictions with the actual ratings. Note that this takes some time due to the dataset size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = algo.test(test_data[[\"User ID\", \"Movie ID\", \"Rating\"]].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8891788222025214"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error([prediction.r_ui for prediction in predictions], [prediction.est for prediction in predictions], squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD<a id=\"svd\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have treated all movies as separate features, but there may be a more efficient way to approach these movies. We can use some latent features that are computed from these movie features. For example, one latent feature may represent horror movies, another may represent romance movies, and some other latent feature may represent movies that combine these two genres. In this case, we care about a person having a liking for a specific genre (shared latent feature) rather than individual movies, which can be far more useful considering the sparsity and the curse of dimensionality.\n",
    "\n",
    "Thankfully, we do not need to manually hunt for latent features. Instead, we use **matrix factorization** (also known as \"matrix decomposition\") to automatically come up with them. While there are many different matrix factorization methods with different requirements, the general idea is to come up with a matrix with a lower [rank](https://en.wikipedia.org/wiki/Rank_(linear_algebra)) (such as 100) that can represent the original matrix that has a higher rank (such as 1000). We essentially do dimensionality reduction and compress our matrix at the expense of some loss of information. Note that the extracted latent features obtained from this process mostly do not directly correspond to just movie genres in a straightforward manner. It is usually harder to logically explain what a specific latent feature represents as it also depends on the ratings themselves, which is one of the reasons we do not do this manually.\n",
    "\n",
    "**Singular Value Decomposition (SVD)** was the top-performing model in the Netflix Prize competition (where this Netflix dataset comes from). SVD is a method of matrix factorization that can work with any $m \\times n$ matrix. This decomposition can be shown as $A = UDV^T$ where $A$ is the original rating matrix, $D$ is a [non-negative diagonal matrix](https://en.wikipedia.org/wiki/Diagonal_matrix), and U and V are orthogonal matrices (so that their multiplications with their inverses produce the [identity matrix](https://en.wikipedia.org/wiki/Identity_matrix)). So, we represent our original matrix as a product of three matrices. Since our matrix has $m \\times n$ dimensions, the other matrices' dimensions are as follows:\n",
    "\n",
    "$A_{[m \\times n]}\\; = U_{[m \\times r]}\\;D_{[r \\times r]}\\;(V_{[n \\times r]}\\;)^T$\n",
    "\n",
    "$U$ keeps $r$ latent features for $m$ users while $V$ keeps $r$ latent features for $n$ movies. So, we can find which concepts a specific user likes, and what a concept (a latente feature) is made of. For example, by looking at a column in $V$, if we see that the column mostly has higher values for horror movies, we may generalize that the column (latent feature) corresponds to mostly horror movies.\n",
    "\n",
    "\"Singular values\" come from the diagonal matrix $D$'s main diagonal values, and they are ordered in decreasing order. These values correspond to the latent features's importance in explaining the rating data.\n",
    "\n",
    "Let us now use an SVD model from scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New matrix shape: (7086, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 43.47775769,  21.33241054,   5.82161217, ...,   0.9787081 ,\n",
       "         -2.07315789,  -1.20243949],\n",
       "       [ 55.14526579,  -7.53942219,   1.32631929, ...,  -1.56086514,\n",
       "         -0.72804528,  -3.14513836],\n",
       "       [ 36.21037551,  -1.32063595, -17.44294342, ...,  -1.08123468,\n",
       "         -0.08469635,  -3.51356671],\n",
       "       ...,\n",
       "       [ 51.95866905,  -4.26442383, -20.12813479, ...,   0.33328047,\n",
       "          2.15592812,   0.89912821],\n",
       "       [ 41.56339151,   8.72930804,  -3.58013643, ...,   1.41795728,\n",
       "          6.08770919,   0.09013284],\n",
       "       [ 49.2966046 ,  -1.60384249, -17.66177853, ...,  -2.54715319,\n",
       "          1.70262439,  -5.10220153]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Creating a model that reduces the features to 50\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "\n",
    "# Fitting the rating matrix\n",
    "svd.fit(rating_matrix)\n",
    "\n",
    "# Obtaining the compressed matrix\n",
    "svd_matrix = svd.transform(rating_matrix)\n",
    "\n",
    "print(\"New matrix shape:\",svd_matrix.shape)\n",
    "svd_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new matrix with 50 columns (latent features) represents $UD$ (the product of left-singular vectors and the diagonal matrix that includes the singular values). To get the right-singular vectors, we can get `components_` of our model. Note that it is transposed as shown in the formula, so we get an $r \\times n$ matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4499)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the first row (right-singular vector), we can see what the first latent feature represents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00181579, 0.00018105, 0.00273837, ..., 0.00251989, 0.00049672,\n",
       "       0.00062123])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.components_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the indices of the top k movies of which this concept comes from and find those movies' names, similar with how we found the top k similar users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top movies that are represented by the first latent feature:\n",
      "Farewell My Concubine - 0.014650784362606242\n",
      "Ned Kelly - 0.012422577669278696\n",
      "Club Dread - 0.01221082474579648\n",
      "Ju-on: The Grudge - 0.008912586429545129\n",
      "Character - 0.0027383670497929825\n",
      "Texasville - 0.0025198915772305167\n",
      "Clifford: Happy Birthday Clifford / Puppy Love - 0.0018704064567584206\n",
      "Dinosaur Planet - 0.0018157948392225887\n",
      "The Rise and Fall of ECW - 0.001485879229431401\n",
      "Rose Hill - 0.001010724673528231\n"
     ]
    }
   ],
   "source": [
    "latent_feature_movies = svd.components_[0]\n",
    "\n",
    "top_k_movies = 10 # Top 10 movies\n",
    "\n",
    "top_movies_for_feature_1 = np.argpartition(latent_feature_movies, kth=top_k_movies)[-top_k_movies:]\n",
    "\n",
    "# Top k movies sorted by their importance for the first feature in descending order\n",
    "top_movie_ids = top_movies_for_feature_1[np.argsort(latent_feature_movies[top_movies_for_feature_1])][::-1] \n",
    "\n",
    "print(\"Top movies that are represented by the first latent feature:\")\n",
    "for movie_index in top_movie_ids:\n",
    "    movie_id = movie_index_to_id[movie_index]\n",
    "    movie_name = movies[movies.ID == movie_id][\"Title\"].values[0]\n",
    "    print(movie_name,\"-\",latent_feature_movies[movie_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we look at the singular values, we see that they are in descending order indeed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3882.97596353, 1169.82619274,  904.52319497,  823.37635718,\n",
       "        705.44688951,  609.92293151,  555.70381709,  533.74181441,\n",
       "        493.3167603 ,  452.43621479,  399.9178529 ,  389.42919073,\n",
       "        361.72135825,  354.60347392,  348.1815648 ,  326.30240863,\n",
       "        315.8157598 ,  309.63365203,  305.76712512,  289.70538565,\n",
       "        282.99566143,  277.33762552,  273.14225577,  268.67629352,\n",
       "        265.60565096,  256.69454795,  250.72649573,  248.39487136,\n",
       "        245.31563617,  240.48207393,  236.669437  ,  231.55413292,\n",
       "        229.7821254 ,  226.33636102,  224.47564986,  220.77360618,\n",
       "        217.99964012,  215.06410539,  211.62003507,  210.2108368 ,\n",
       "        207.10874191,  204.5540599 ,  203.65739931,  201.74601006,\n",
       "        199.31603911,  197.30602874,  196.05406716,  191.59508778,\n",
       "        190.54932896,  188.1514552 ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7681782408534867"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(svd_matrix, svd.components_)[0][0]/np.dot(svd_matrix, svd.components_)[0].mean()*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have 50 concepts, we have 50 singular values.\n",
    "\n",
    "This approach is considered a model-based approach since we do not work with individual ratings of users for individual movies. Now, let us see how we can predict a rating using Surprise package and SVD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=1333, iid=1, r_ui=None, est=3.17485308155212, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# We set the number of concepts to 50 again\n",
    "surprise_svd = SVD(n_factors=50)\n",
    "\n",
    "# We fit our training data\n",
    "surprise_svd.fit(training_data)\n",
    "\n",
    "# We can now predict the first user's rating for the first movie\n",
    "surprise_svd.test([[1333,1,None]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is close to our previous try. Note that the number of concepts is arbitrarily set here to 50. You might want to use cross-validation to prefer a number that yields the best results."
   ]
  }
 ],
 "metadata": {
  "author": "Ã–zgÃ¼n Ozan KÄ±lÄ±Ã§",
  "institute": "Informatics Institute, Middle East Technical University",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
